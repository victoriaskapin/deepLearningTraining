{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vfLOURR2gHH"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/institutohumai/cursos-python/blob/master/DeepLearning/3_Redes_Multicapa/ejercicios/ejercicios.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIfRkWPFFAoh"
      },
      "source": [
        "# Ejercicios Clase 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrjQc1jFzKax"
      },
      "source": [
        "En este notebook vamos a usar MLPs para generar un modelo clasificador sobre FashionMNIST así que muchas de las funciones que usamos en los ejercicios de la clase 2 te serán muy útiles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXptOn-CVs2n"
      },
      "source": [
        "## Ejercicio 1:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVlWPVyn5PW1"
      },
      "source": [
        "Generar un modelo perceptron multicapa con 2 capas ocultas de 512 y 128 neuronas respectivamente para clasificación sobre el dataset FashionMNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5s8UWRi1zqXD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "#from IPython import display\n",
        "from torchvision import transforms\n",
        "from torch.utils import data\n",
        "\n",
        "\n",
        "net = nn.Sequential(nn.Flatten(),\n",
        "                    nn.Linear(784, 512),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(512, 128),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(128, 10))\n",
        "\n",
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.normal_(m.weight, std=0.01)\n",
        "\n",
        "net.apply(init_weights);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ntELWGPIpoB"
      },
      "source": [
        "## Ejercicio 2\n",
        "\n",
        "Entrene el modelo por 10 épocas con un tamaño de lote de 256 y un learning rate de 0.3. (Le recomendamos reutilizar las funciones modularizadas de los ejercicios de la clase 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KIIQUloXX-PA"
      },
      "outputs": [],
      "source": [
        "#ingresa tu código aquí\n",
        "batch_size, lr, num_epochs = 256, 0.3, 10\n",
        "loss = nn.CrossEntropyLoss(reduction='none')\n",
        "trainer = torch.optim.SGD(net.parameters(), lr=lr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data_fashion_mnist(batch_size, resize=None):\n",
        "    trans = [transforms.ToTensor()]\n",
        "    if resize:\n",
        "        trans.insert(0, transforms.Resize(resize))\n",
        "    trans = transforms.Compose(trans)\n",
        "    mnist_train = torchvision.datasets.FashionMNIST(\n",
        "        root=\"../data\", train=True, transform=trans, download=True)\n",
        "    mnist_test = torchvision.datasets.FashionMNIST(\n",
        "        root=\"../data\", train=False, transform=trans, download=True)\n",
        "    return (data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
        "                            num_workers=1),\n",
        "            data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
        "                            num_workers=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def accuracy(y_hat, y):\n",
        "    \"\"\"Compute the number of correct predictions.\"\"\"\n",
        "    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "        y_hat = y_hat.argmax(axis=1)\n",
        "    cmp = y_hat.type(y.dtype) == y\n",
        "    return float(cmp.type(y.dtype).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_iter, test_iter = load_data_fashion_mnist(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(train_iter,net,loss_fn, optimizer,accuracy_fn, trackers):\n",
        "    for X, y in train_iter:\n",
        "        optimizer.zero_grad()\n",
        "        y_hat = net(X)\n",
        "        l = loss_fn(y_hat, y)\n",
        "        l.mean().backward()\n",
        "        optimizer.step()\n",
        "        with torch.no_grad():\n",
        "            trackers['epoch_loss'] += l.sum()\n",
        "            trackers['epoch_acc'] += accuracy_fn(y_hat, y)\n",
        "            trackers['num_samples'] += len(X)\n",
        "    \n",
        "\n",
        "def test_epoch(test_iter,net,accuracy_fn, trackers):\n",
        "    for X, y in test_iter:\n",
        "        with torch.no_grad():\n",
        "            y_hat = net(X)\n",
        "            trackers['test_acc'] += accuracy_fn(y_hat, y)\n",
        "            trackers['num_test_samples'] += len(X)\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(net, train_iter, test_iter, loss, num_epochs, trainer, accuracy):\n",
        "    trackers = {'epoch_loss': 0.,\n",
        "                'epoch_acc': 0.,\n",
        "                'num_samples': 0.,\n",
        "                'test_acc': 0.,\n",
        "                'num_test_samples': 0.\n",
        "                }\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        trackers['epoch_loss'] = 0.\n",
        "        trackers['epoch_acc'] = 0.\n",
        "        trackers['num_samples'] = 0.\n",
        "        trackers['test_acc'] = 0.\n",
        "        trackers['num_test_samples'] = 0.\n",
        "        train_epoch(train_iter,net,loss, trainer,accuracy, trackers)\n",
        "        test_epoch(test_iter,net,accuracy, trackers)\n",
        "        print(f'Epoch {epoch+1}: loss {trackers[\"epoch_loss\"]/trackers[\"num_samples\"]:.3f}, accuracy {trackers[\"epoch_acc\"]/trackers[\"num_samples\"]:.3f}, test accuracy {trackers[\"test_acc\"]/trackers[\"num_test_samples\"]:.3f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: loss 1.180, accuracy 0.544, test accuracy 0.722\n",
            "Epoch 2: loss 0.568, accuracy 0.791, test accuracy 0.594\n",
            "Epoch 3: loss 0.469, accuracy 0.828, test accuracy 0.817\n",
            "Epoch 4: loss 0.418, accuracy 0.846, test accuracy 0.823\n",
            "Epoch 5: loss 0.388, accuracy 0.857, test accuracy 0.797\n",
            "Epoch 6: loss 0.365, accuracy 0.864, test accuracy 0.855\n",
            "Epoch 7: loss 0.351, accuracy 0.872, test accuracy 0.804\n",
            "Epoch 8: loss 0.335, accuracy 0.875, test accuracy 0.863\n",
            "Epoch 9: loss 0.321, accuracy 0.880, test accuracy 0.803\n",
            "Epoch 10: loss 0.308, accuracy 0.885, test accuracy 0.860\n"
          ]
        }
      ],
      "source": [
        "train(net, train_iter, test_iter, loss, num_epochs, trainer, accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH0Tag93XCct"
      },
      "source": [
        "## Ejercicio 3 :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJOmdokbXCcu"
      },
      "source": [
        "A partir del modelo anterior, analice que ocurre si en lugar de entrenar 10 épocas, entrena 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1eOc5tisYNHZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: loss 0.301, accuracy 0.887, test accuracy 0.847\n",
            "Epoch 2: loss 0.296, accuracy 0.889, test accuracy 0.874\n",
            "Epoch 3: loss 0.286, accuracy 0.893, test accuracy 0.875\n",
            "Epoch 4: loss 0.281, accuracy 0.895, test accuracy 0.858\n",
            "Epoch 5: loss 0.269, accuracy 0.899, test accuracy 0.863\n",
            "Epoch 6: loss 0.261, accuracy 0.902, test accuracy 0.875\n",
            "Epoch 7: loss 0.256, accuracy 0.904, test accuracy 0.879\n",
            "Epoch 8: loss 0.248, accuracy 0.908, test accuracy 0.872\n",
            "Epoch 9: loss 0.240, accuracy 0.911, test accuracy 0.879\n",
            "Epoch 10: loss 0.236, accuracy 0.910, test accuracy 0.879\n",
            "Epoch 11: loss 0.230, accuracy 0.914, test accuracy 0.856\n",
            "Epoch 12: loss 0.227, accuracy 0.914, test accuracy 0.867\n",
            "Epoch 13: loss 0.756, accuracy 0.853, test accuracy 0.780\n",
            "Epoch 14: loss 0.430, accuracy 0.846, test accuracy 0.851\n",
            "Epoch 15: loss 0.321, accuracy 0.883, test accuracy 0.843\n",
            "Epoch 16: loss 0.300, accuracy 0.889, test accuracy 0.868\n",
            "Epoch 17: loss 0.277, accuracy 0.896, test accuracy 0.871\n",
            "Epoch 18: loss 0.262, accuracy 0.903, test accuracy 0.821\n",
            "Epoch 19: loss 0.263, accuracy 0.903, test accuracy 0.847\n",
            "Epoch 20: loss 0.246, accuracy 0.907, test accuracy 0.855\n"
          ]
        }
      ],
      "source": [
        "#ingresa tu código aquí\n",
        "num_epochs = 20\n",
        "train(net, train_iter, test_iter, loss, num_epochs, trainer, accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptvfEmUIcf0-"
      },
      "source": [
        "## Ejercicio 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL8cyma5ciJa"
      },
      "source": [
        "Aumente el learning rate a 1 y entrene nuevamente. ¿Cómo puede explicar lo que pasó?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gMEUXxHac3Ny"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: loss nan, accuracy 0.108, test accuracy 0.100\n",
            "Epoch 2: loss nan, accuracy 0.100, test accuracy 0.100\n",
            "Epoch 3: loss nan, accuracy 0.100, test accuracy 0.100\n",
            "Epoch 4: loss nan, accuracy 0.100, test accuracy 0.100\n",
            "Epoch 5: loss nan, accuracy 0.100, test accuracy 0.100\n",
            "Epoch 6: loss nan, accuracy 0.100, test accuracy 0.100\n",
            "Epoch 7: loss nan, accuracy 0.100, test accuracy 0.100\n",
            "Epoch 8: loss nan, accuracy 0.100, test accuracy 0.100\n",
            "Epoch 9: loss nan, accuracy 0.100, test accuracy 0.100\n",
            "Epoch 10: loss nan, accuracy 0.100, test accuracy 0.100\n",
            "Epoch 11: loss nan, accuracy 0.100, test accuracy 0.100\n",
            "Epoch 12: loss nan, accuracy 0.100, test accuracy 0.100\n",
            "Epoch 13: loss nan, accuracy 0.100, test accuracy 0.100\n",
            "Epoch 14: loss nan, accuracy 0.100, test accuracy 0.100\n",
            "Epoch 15: loss nan, accuracy 0.100, test accuracy 0.100\n",
            "Epoch 16: loss nan, accuracy 0.100, test accuracy 0.100\n",
            "Epoch 17: loss nan, accuracy 0.100, test accuracy 0.100\n",
            "Epoch 18: loss nan, accuracy 0.100, test accuracy 0.100\n",
            "Epoch 19: loss nan, accuracy 0.100, test accuracy 0.100\n",
            "Epoch 20: loss nan, accuracy 0.100, test accuracy 0.100\n"
          ]
        }
      ],
      "source": [
        "lr = 1 \n",
        "trainer = torch.optim.SGD(net.parameters(), lr=lr)\n",
        "num_epochs = 20\n",
        "train(net, train_iter, test_iter, loss, num_epochs, trainer, accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpPB6eo7YcUy"
      },
      "source": [
        "## Ejercicio 5:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf0axPgXYcU0"
      },
      "source": [
        "Analize el efecto de cambiar las funciones de activación en el accurracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1aVS2IaOYcU2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: loss 0.855, accuracy 0.721, test accuracy 0.776\n",
            "Epoch 2: loss 0.525, accuracy 0.812, test accuracy 0.807\n",
            "Epoch 3: loss 0.478, accuracy 0.829, test accuracy 0.779\n",
            "Epoch 4: loss 0.452, accuracy 0.838, test accuracy 0.821\n",
            "Epoch 5: loss 0.429, accuracy 0.847, test accuracy 0.841\n",
            "Epoch 6: loss 0.415, accuracy 0.852, test accuracy 0.823\n",
            "Epoch 7: loss 0.407, accuracy 0.853, test accuracy 0.797\n",
            "Epoch 8: loss 0.391, accuracy 0.859, test accuracy 0.827\n",
            "Epoch 9: loss 0.388, accuracy 0.860, test accuracy 0.823\n",
            "Epoch 10: loss 0.377, accuracy 0.864, test accuracy 0.833\n"
          ]
        }
      ],
      "source": [
        "#ingresa tu código aquí\n",
        "net = nn.Sequential(nn.Flatten(),\n",
        "                    nn.Linear(784, 512),\n",
        "                    nn.Tanh(),\n",
        "                    nn.Linear(512, 128),\n",
        "                    nn.Tanh(),\n",
        "                    nn.Linear(128, 10))\n",
        "\n",
        "lr= 0.1\n",
        "trainer = torch.optim.SGD(net.parameters(), lr=lr)\n",
        "num_epochs = 10\n",
        "train(net, train_iter, test_iter, loss, num_epochs, trainer, accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMzoVF_5bARh"
      },
      "source": [
        "## Ejercicio 6:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj9XuB7LbARi"
      },
      "source": [
        "Ahora genere un tercer modelo en donde ambas capas tengan 1024 neuronas. Analice si produjo algún cambio en los rendimientos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9sKhx7oDbARk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: loss 0.357, accuracy 0.872, test accuracy 0.857\n",
            "Epoch 2: loss 0.354, accuracy 0.873, test accuracy 0.857\n",
            "Epoch 3: loss 0.354, accuracy 0.873, test accuracy 0.859\n",
            "Epoch 4: loss 0.353, accuracy 0.874, test accuracy 0.858\n",
            "Epoch 5: loss 0.352, accuracy 0.874, test accuracy 0.859\n",
            "Epoch 6: loss 0.351, accuracy 0.874, test accuracy 0.858\n",
            "Epoch 7: loss 0.351, accuracy 0.874, test accuracy 0.859\n",
            "Epoch 8: loss 0.350, accuracy 0.875, test accuracy 0.859\n",
            "Epoch 9: loss 0.349, accuracy 0.875, test accuracy 0.860\n",
            "Epoch 10: loss 0.348, accuracy 0.875, test accuracy 0.861\n",
            "Epoch 11: loss 0.348, accuracy 0.875, test accuracy 0.860\n",
            "Epoch 12: loss 0.347, accuracy 0.875, test accuracy 0.860\n",
            "Epoch 13: loss 0.346, accuracy 0.876, test accuracy 0.860\n",
            "Epoch 14: loss 0.345, accuracy 0.876, test accuracy 0.860\n",
            "Epoch 15: loss 0.345, accuracy 0.876, test accuracy 0.861\n",
            "Epoch 16: loss 0.344, accuracy 0.876, test accuracy 0.861\n",
            "Epoch 17: loss 0.343, accuracy 0.877, test accuracy 0.861\n",
            "Epoch 18: loss 0.343, accuracy 0.877, test accuracy 0.860\n",
            "Epoch 19: loss 0.342, accuracy 0.877, test accuracy 0.861\n",
            "Epoch 20: loss 0.342, accuracy 0.878, test accuracy 0.861\n"
          ]
        }
      ],
      "source": [
        "#ingresa tu código aquí\n",
        "et = nn.Sequential(nn.Flatten(),\n",
        "                    nn.Linear(784, 1024),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(1024, 1024),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(1024, 10))\n",
        "\n",
        "lr= 0.01\n",
        "trainer = torch.optim.SGD(net.parameters(), lr=lr)\n",
        "num_epochs = 20\n",
        "train(net, train_iter, test_iter, loss, num_epochs, trainer, accuracy)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ejercicios.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
